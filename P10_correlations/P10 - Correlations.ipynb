{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#009440; padding: 0px; background-size:cover; background-opacity:50%; border-radius:5px; height:300px\">\n",
    "    <div style=\"margin: 5px; padding: 10px;\">\n",
    "    <h1 style=\"color:#00000\">Geophysical Data Acquisition and Analysis</h1>\n",
    "    <h4 style=\"color:#dddddd\">LMU, 08 August 2019</h4>\n",
    "        <h4 style=\"color:#dddddd\">Authors: Ceri Nunn, Stefanie Donner, Alice Gabriel, CÃ©line Hadziioannou, Stephanie Wollherr, Taufiqurrahman</h4>\n",
    "    </div>\n",
    "    <div style=\"float:right; margin: 10px; padding: 20px; background:rgba(255,255,255,0.7); width: 70%; height: 150px\">\n",
    "        <div style=\"position:relative; top:30%; transform: translateY(-50%)\">\n",
    "        <div style=\"font-size: x-large; font-weight:900; color:rgba(0,0,0,0.8); line-height:100%\">P10 - Correlations</div>\n",
    "        </div>\n",
    "    </div>\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Please, do not forget to execute Cell 1 first!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Preparation for programming\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib notebook\n",
    "from scipy import interpolate, signal\n",
    "from time import *\n",
    "from obspy import *\n",
    "from obspy.core import read, UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import glob\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "plt.rcParams['lines.linewidth'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with the discrete form of the cross covariance function: \n",
    "\n",
    "$$\\large{(f \\star g) [n] \\overset{\\mathrm{def}}{=} \\sum_{m=-\\infty}^{\\infty} f^*\\ [m]\\ g[m + n]}$$\n",
    "\n",
    "We start with a simple example: \n",
    "\n",
    "$$f = [0,1,2,1,0,0,0]$$\n",
    "$$g = [0,2,4,2,0,0,0]$$\n",
    "\n",
    "We can calculate the cross-covariance function (without shifting the signals): \n",
    "\n",
    "$$corr(f,g) = 0 * 0\\ +\\ 1 * 2\\ +\\ 2 * 4\\ +\\ 1 * 2\\ +\\ 0 * 0\\ +\\ 0 * 0\\ +\\ 0 * 0$$\n",
    "\n",
    "$$=12$$\n",
    "\n",
    "In many cases, it is helpful to normalize the cross-covariance function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "We are going to use the numpy package to check the calculation above. \n",
    "\n",
    "**1a)** Read the explanation above, as well as the code below, and check that you understand it. \n",
    "\n",
    "**1b)** Experiment with the parameter 'mode'. The options are 'full, 'valid' and 'same'. Read the documenation! What does the parameter do? What affect does it have on the length of the output signal. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1a\n",
    "\n",
    "plt.ioff()\n",
    "# the signals to cross-correlate\n",
    "f = [0,1,2,1,0,0,0]\n",
    "g = [0,2,4,2,0,0,0]\n",
    "\n",
    "# calculate the correlation\n",
    "xcorr1 = np.correlate(f,g,mode='same')\n",
    "# Is the cross correlation the same value that we have already calculated? \n",
    "\n",
    "print(\"Simple correlation function: \")\n",
    "print(xcorr1)\n",
    "dt = 1\n",
    "\n",
    "# make array with time shifts in seconds corresponding to cc function\n",
    "# note that bound and cc_t both depend on the length and mode of the \n",
    "# cross correlation function\n",
    "bound = ((len(xcorr1)-1)*dt)/2 \n",
    "cc_t = np.linspace(-bound, bound, len(xcorr1))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('signals to correlate')\n",
    "plt.plot(f, label='f')\n",
    "plt.plot(g, label='g')\n",
    "plt.legend()\n",
    "\n",
    "# Note, that with this short example, the correlation plot only works in 'same' or 'full' mode.\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('Correlation')\n",
    "plt.plot(cc_t, xcorr1, 'o', label='Correlation')\n",
    "plt.plot(cc_t, xcorr1,'r')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - correlating simple signals\n",
    "This exercise will show you how you can determine the lag between two signals with the correlation. You will also see what can happen when you correlate noisy signals. \n",
    "\n",
    "Have a look at the code. It generates a Ricker wavelet (rk) and shifts it by a certain lag to create the second signal (rk2). On a shifted signal, there is the option to add random noise (rkn). \n",
    "The correlation function between both signals is calculated and shown in the plot. \n",
    "\n",
    "\n",
    "**2a)** Explain the meaning of the red line on the correlation function plot. Why does the time axis run from -100 to 100 seconds? Can you use the correlation function to determine the lag between the two signals? Use the option to zoom in (with xlim, see code) if needed. Does this lag value match the real lag? \n",
    "\n",
    "**2b)** Increase the noiselevel. Try some values between 0.1 and 1. Describe what you see happening to the signals, and to the correlation function. Can the lag between the signals still be determined? What happens to the correlation coefficient? What does this mean?\n",
    "\n",
    "**2c)** In the line where the correlation function of rk and rk2 is calculated: change the order of 'rk' and 'rk2'. What happens to the output? Which property of the correlation does this illustrate? \n",
    "\n",
    "*Write your answers in the markup cell below the plots!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2a:\n",
    "\n",
    "plt.ioff()\n",
    "lag = 3       # lag in seconds, initial value 3\n",
    "noiselevel = 0.05  # noise level to add, initial value 0.1\n",
    "\n",
    "# create time vector\n",
    "npts = 4096     # number of samples, initial value: 4096\n",
    "dt = 0.025      # sample rate, initial value:0.025 \n",
    "t = np.linspace(0,(npts-1)*dt,npts)\n",
    "\n",
    "# create original signal: Ricker wavelet\n",
    "rk = signal.ricker(npts, 20.0)         # 2nd number = width of wavelet, intial value: 20.0 \n",
    "# create shifted signal\n",
    "rk2 = np.zeros(rk.size)\n",
    "#rk2[int(lag/dt):] = rk[:int(-lag/dt)]\n",
    "rk2 = np.roll(rk,int(-lag/dt))\n",
    "\n",
    "# create a noisy signal\n",
    "rkn = rk  + noiselevel * np.random.rand(rk.size) \n",
    "rkn -= rkn.mean()\n",
    "\n",
    "# calculate the correlation function between signal 1 and signal 2\n",
    "xcorr1 = np.correlate(rk, rk2, mode='full')\n",
    "\n",
    "# make array with time shifts in seconds corresponding to cc function\n",
    "# note that bound and cc_t both depend on the length and hence the \n",
    "# mode of the cross correlation function\n",
    "bound = ((len(xcorr1)-1)*dt)/2 \n",
    "cc_t = np.linspace(-bound, bound, len(xcorr1))\n",
    "\n",
    "# extract the maximum value from the correlation function\n",
    "peak_index = abs(xcorr1).argmax()\n",
    "\n",
    "# calculate the correlation function between noisy signal and signal 2\n",
    "xcorrn = np.correlate(rkn, rk2, mode='full')\n",
    "# extract the location of the maximum value from the correlation function\n",
    "peak_index_n = abs(xcorrn).argmax()\n",
    "norm = (np.sum(rkn**2)*np.sum(rk**2))**0.5\n",
    "corrcoef = xcorrn[peak_index_n]/norm\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.title('signals to correlate')\n",
    "plt.plot(t,rk, label='signal 1')\n",
    "plt.plot(t,rk2, label='signal 2')\n",
    "plt.xlabel('time[s]')\n",
    "plt.xlim((0, npts*dt))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(t,rkn, label='noisy signal')\n",
    "plt.plot(t,rk2, label='signal 2')\n",
    "plt.xlim((0, npts*dt))\n",
    "plt.xlabel('time[s]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.title('correlation function')\n",
    "plt.plot(cc_t, xcorr1, label='signal 1 & signal 2')\n",
    "plt.plot(cc_t, xcorrn, label='noisy signal & signal 2')\n",
    "plt.legend()\n",
    "plt.xlabel('time[s]')\n",
    "plt.xlim((-npts*dt, npts*dt))\n",
    "# uncomment the following line to zoom in \n",
    "# plt.xlim((-10,10))\n",
    "plt.xlabel('time[s]')\n",
    "\n",
    "# prevent subplots overlapping\n",
    "plt.tight_layout() \n",
    "plt.show()\n",
    "\n",
    "print(\"shift between signal 1 and signal 2: %f seconds \\n \" % cc_t[peak_index])\n",
    "print(\"shift between noisy signal and signal 2: %f seconds\" % cc_t[peak_index_n])\n",
    "print(\"correlation coefficient between noisy signal and signal 2: \", corrcoef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2, continued\n",
    "Here, you will use signals from an earthquake, measured at two different locations. \n",
    "\n",
    "**2d)** Try to determine the lag between signal 1 and signal 2 from the seismogram signals (first plot). Zoom in using the 'xlim' line and adjust the limits if necessary. Do the same using the correlation signal in the second plot. What values to you find? Does this correspond to the value determined by the code by finding the maximum of the correlation? \n",
    "\n",
    "**2e)** Answer the question **2d)** for signal 2 and signal 3. What do you notice about the correlation coefficient? What does this mean? Set the noise level to zero, then also incrementally increase the noise level. What happens to the correlation coefficient?\n",
    "\n",
    "**2f)** Given that this is the same earthquake measured at two different seismometers. If you know the location of the seismometers, what could you use the lag time you determined for? \n",
    "\n",
    "*Write your answers in the markup cell below the plots!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2b: \n",
    "## using example data of two small earthquakes\n",
    "\n",
    "plt.ioff()\n",
    "st1 = read('DATA/seismogram1.sac')\n",
    "st2 = read('DATA/seismogram2.sac')\n",
    "st3 = st2.copy()\n",
    "\n",
    "#select the vertical component of the seismogram\n",
    "tr1 = st1.select(component=\"Z\")[0]\n",
    "tr2 = st2.select(component=\"Z\")[0]\n",
    "tr3 = tr2.copy()\n",
    "\n",
    "\n",
    "\n",
    "dt = tr1.stats.delta\n",
    "\n",
    "#divide by standard deviation\n",
    "tr1.data = tr1.data/tr1.std()\n",
    "tr2.data = tr2.data/tr2.std()\n",
    "tr3.data = tr3.data/tr3.std()\n",
    "\n",
    "# add random noise to signal:\n",
    "noiselevel = 0.2 # initial value 0.2 \n",
    "tr3.data = tr3.data * -1.0 + noiselevel * tr3.max() * np.random.rand(tr3.data.size) \n",
    "tr3.detrend('linear')\n",
    "\n",
    "print(st1, '\\n', st2, '\\n', st3)\n",
    "\n",
    "# calculate cross-correlation, lag and correlation coefficient\n",
    "xcorr1 = np.correlate(tr1.data, tr2.data, mode='full')\n",
    "peak_index1 = abs(xcorr1).argmax()\n",
    "\n",
    "cc1 = np.corrcoef(tr1.data, tr2.data)[0,0]\n",
    "norm = (np.sum(tr1.data**2)*np.sum(tr2.data**2))**0.5\n",
    "cc1 = xcorr1[peak_index1]/norm\n",
    "\n",
    "xcorr2 = np.correlate(tr1.data, tr3.data, mode='full')\n",
    "peak_index2 = abs(xcorr2).argmax()\n",
    "norm = (np.sum(tr1.data**2)*np.sum(tr3.data**2))**0.5\n",
    "cc2 = xcorr2[peak_index2]/norm\n",
    "\n",
    "# make array with time shifts in seconds corresponding to cc function\n",
    "# note that bound and cc_t both depend on the length and mode of the \n",
    "# cross correlation function\n",
    "bound = ((len(xcorr1)-1)*dt)/2 \n",
    "cc_t = np.linspace(-bound, bound, len(xcorr1))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.title('normalized seismograms')\n",
    "plt.plot(tr1.times(), tr1.data/abs(tr1.max()), label='sig1')\n",
    "plt.plot(tr2.times(), tr2.data/abs(tr2.max()), label='sig2')\n",
    "plt.plot(tr3.times(), tr3.data/abs(tr3.max()), label='sig3')\n",
    "plt.legend()\n",
    "# uncomment the following line to zoom in to the first plot if needed\n",
    "#plt.xlim((0.5, 0.6))\n",
    "plt.xlabel('time[s]')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.title('correlation signals')\n",
    "plt.plot(cc_t, xcorr1, label='corr sig1 & sig2')\n",
    "# uncomment the following line to zoom in to the first plot if needed\n",
    "#plt.xlim((0.01, 0.02))\n",
    "plt.legend()\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(cc_t, xcorr2, label='corr sig1 & sig3')\n",
    "# uncomment the following line to zoom in to the first plot if needed\n",
    "#plt.xlim((0.1, 0.2))\n",
    "plt.legend()\n",
    "plt.xlabel('time[s]')\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()\n",
    "\n",
    "print(\"shift between signal 1 and signal 2: %f seconds\" % cc_t[peak_index1])\n",
    "print(\"correlation coefficient between signal 1 and signal 2: %f \\n\" % cc1)\n",
    "\n",
    "print(\"shift between noisy signal and signal 2: %f seconds\" % cc_t[peak_index2])\n",
    "print(\"correlation coefficient between noisy signal and signal 2: %f\"% cc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: ...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Backazimuth of an earthquake\n",
    "\n",
    "In this exercise you will see an application of the correlation. \n",
    "\n",
    "If you measure the transverse acceleration (using a \"traditional\" seismometer) and the rotation rate (using for example a ring laser) at the same location, the waveforms should be the same. This only holds if the horizontal components (N, E) of the seismometer record are oriented to point towards the earthquake source location: towards \"radial\" (R, pointing to source) and \"transverse\" (T, perpendicular to the great circle path connecting source and receiver). \n",
    "\n",
    "If you don't know where the source was, you can exploit this property by using the correlation coefficient. In this exercise, a seismogram is cut into smaller time windows. For each time window, the two horizontal components (N, E) are oriented towards different backazimuth angles from 0-360, giving us R, T components for each angle. \n",
    "\n",
    "For each angle between 0-360, the waveform of the transverse (T) component is compared to the waveform for rotation. If the waveforms match, you know you have the correct angle and are pointing towards the source. \n",
    "\n",
    "**3a)** Can you explain why the correlation coeffcient is used for this?\n",
    "\n",
    "In Cell 3a, there is the option to download signals for four different events. Choose one of events 1-3 (uncomment the corresponding 't1' and 't2') and run cell 3a. The processing described above is performed in cell 3b, and cell 3c plots the results.  \n",
    "\n",
    "**3b)** In the second plot, red colors indicate good positive correlation (up to 1), grey stands for negative correlation (down to -1). Can you say towards which backazimuth the earthquake occurred? Why are the grey colors always separated by 180 degrees from the red colors? \n",
    "\n",
    "**3c)** Choose event 4 and run Cells 3a-3c. What does the backazimuth plot look like? Now set the bandpass filter to filter between 0.1 and 0.2 Hz. Re-run Cells 3a, 3b and 3c. What has changed? How do you explain this? \n",
    "\n",
    "*Write your answers in the markup cell below the plots!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3a: \n",
    "\n",
    "plt.ioff()\n",
    "#event 1: M7.0 Kumamoto 2016.04.15\n",
    "#t1 = UTCDateTime(\"2016-04-15 16:55:06\")\n",
    "#t2 = UTCDateTime(\"2016-04-15 17:55:06\")\n",
    "\n",
    "#event 2: M9.0 Tohoku 2011.03.1\n",
    "#t1 = UTCDateTime(\"2011-03-11T05:00:00.000\")\n",
    "#t2 = UTCDateTime(\"2011-03-11T10:00:00.000\")\n",
    "\n",
    "#event 3: M7.9 Nepal 2015.04.25\n",
    "#t1 = UTCDateTime(\"2015-04-25T06:08:58.300000\")\n",
    "#t2 = UTCDateTime(\"2015-04-25T09:11:58.300000\")\n",
    "\n",
    "#event 4: ???? \n",
    "t1 = UTCDateTime(\"2012-12-27T06:00:00.000000\")\n",
    "t2 = UTCDateTime(\"2012-12-27T09:00:00.000000\")\n",
    "\n",
    "\n",
    "fdsn_client = Client('BGR')\n",
    "# Fetch waveform from FDSN web service into a ObsPy stream object\n",
    "# and automatically attach correct response\n",
    "\n",
    "# broadband seismometer in Wettzell, Germany:\n",
    "st1 = fdsn_client.get_waveforms(network='GR', station='WET', location='',\n",
    "                               channel='BH*', starttime=t1, endtime=t2,\n",
    "                               attach_response=True)\n",
    "# define a filter band to prevent amplifying noise during the deconvolution\n",
    "pre_filt = (0.005, 0.006, 30.0, 35.0)\n",
    "st1.remove_response(output='ACC', pre_filt=pre_filt)\n",
    "\n",
    "# ring laser rotational instrument in Wettzell, Germany:\n",
    "fdsn_client = Client('LMU')\n",
    "st2 = fdsn_client.get_waveforms(network='BW', station='RLAS', location='',\n",
    "                               channel='BJZ', starttime=t1, endtime=t2,\n",
    "                               attach_response=True)\n",
    "\n",
    "\n",
    "# Tohoku event\n",
    "# if you do not have an internet connection: comment everything above and uncomment the following two lines\n",
    "#st1 = read('DATA/GR.WET.2011-03-11.mseed')\n",
    "#st2 = read('DATA/BW.RLAS.2011-03-11.mseed')\n",
    "\n",
    "print(st1, '\\n', st2)\n",
    "st1.plot()\n",
    "st2.plot()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 3b:\n",
    "\n",
    "plt.ioff()\n",
    "## bandpass frequencies \n",
    "freq_start=0.02      # start of bandpass in Hz, initial value 0.02\n",
    "freq_end=0.1        # end of bandpass in Hz, initial value 0.1\n",
    "\n",
    "## backazimuth vector\n",
    "BAZstep = 10   # BAZ sampling interval in degrees, initial value 10\n",
    "BAZ = np.linspace(0,360-BAZstep,360//BAZstep)\n",
    "\n",
    "## sliding timewindow parameters \n",
    "startminutes=0      # start first window after [startminutes] \n",
    "lwin=200            # window length in seconds\n",
    "dwin=100       # window shift in seconds; if dwin < lwin : overlapping windows\n",
    "\n",
    "## prepare signal\n",
    "st_bb = st1.copy()    # broadband seismometer\n",
    "st_rl = st2.copy()    # rotational instrument (ring laser)\n",
    "\n",
    "#trim both to same length\n",
    "# if this cell is taking much too long, try trimming the signal even shorter (but keep the earthquake!)\n",
    "st_bb.trim(t1+500, t2-500)\n",
    "st_rl.trim(t1+500, t2-500)\n",
    "\n",
    "#bandpass filter\n",
    "st_rl.filter('bandpass', freqmin=freq_start, freqmax=freq_end)\n",
    "st_bb.filter('bandpass', freqmin=freq_start, freqmax=freq_end)\n",
    "\n",
    "fs = st_bb[0].stats.sampling_rate  # sampling frequency\n",
    "    \n",
    "## sliding windows in number of samples\n",
    "startwin=startminutes*fs*60 \n",
    "\n",
    "lwins=int(lwin*fs)   # window length in samples\n",
    "dwins=int(dwin*fs)   # window shift in samples\n",
    "# number of windows: (trace length-startwin-lwin)/lwin\n",
    "#nwin=(st[0].stats.npts-startwin-lwins)//(lwins+dwins)\n",
    "nwin=int((st_bb[0].stats.npts-startwin-lwins)//dwins)\n",
    "\n",
    "## initialize vectors\n",
    "trans=np.zeros((len(BAZ),int(lwins),int(nwin)))   # vector for rotated transverse acc\n",
    "corr_zerolag=np.zeros((len(BAZ),nwin))\n",
    "corr2_zerolag=np.zeros((len(BAZ),nwin),dtype='int32')\n",
    "\n",
    "imax=np.zeros(nwin,dtype='int32')\n",
    "cohmax=np.zeros(nwin)\n",
    "\n",
    "\n",
    "## for each sliding window\n",
    "for iw in range(nwin):\n",
    "    \n",
    "    #rzd = st_rl.select(channel=\"BJZ\")[0].data\n",
    "    rzd = st_rl.select(channel=\"BJZ\")[0].data\n",
    "\n",
    "    ted = st_bb.select(channel=\"BHE\")[0].data\n",
    "    tnd = st_bb.select(channel=\"BHN\")[0].data\n",
    "\n",
    "    rz1 = rzd[int(startwin+iw*dwins):int(startwin+iw*dwins+lwins)]\n",
    "    te1 = ted[int(startwin+iw*dwins):int(startwin+iw*dwins+lwins)]\n",
    "    tn1 = tnd[int(startwin+iw*dwins):int(startwin+iw*dwins+lwins)]\n",
    "    \n",
    "    ## for each backazimuth angle: \n",
    "    for ia in range(360//BAZstep):\n",
    "       \n",
    "        #Compute transversal and radial comp. for all windows, BAZsteps, sample points\n",
    "        ##  rotate broadband signal to BAZ angle\n",
    "        \n",
    "        trans[ia,:,iw] = te1*np.cos((BAZ[ia]+180)*np.pi/180)-tn1*np.sin((BAZ[ia]+180)*np.pi/180)\n",
    "    \n",
    "        ## calculate correlation coefficient:\n",
    "        denom = np.sqrt(np.dot(rz1,rz1)*np.dot(trans[ia,:,iw],trans[ia,:,iw]))\n",
    "        corr = np.convolve(rz1[::-1],trans[ia,:,iw])/denom\n",
    "\n",
    "        corr_zerolag[ia,iw] = corr[lwins]   # pick value at center\n",
    "\n",
    "    ## maximum coherence for each window iw:\n",
    "    imax[iw] = int(np.argmax(abs(corr_zerolag[:,iw]))) # index of max\n",
    "    cohmax[iw] = corr_zerolag[imax[iw],iw]   # corrcoef at max\n",
    "    \n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Cell 3c:\n",
    "\n",
    "plt.ioff()\n",
    "# plot result\n",
    "# this uses data fetched in Cell 3a and prepared in Cell 3b\n",
    "\n",
    "# create time vector for the backazimuth plot (uses sliding timewindow lengths)\n",
    "timevec = np.linspace(0,nwin*(lwin-dwin) + dwin, nwin)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('Rotation and transverse signal')\n",
    "plt.plot(st_rl[0].times(), st_rl[0].data, 'r', label='rotation')\n",
    "plt.plot(st_bb[0].times(), st_bb[0].data, 'k', label='horizontal')\n",
    "plt.xlabel('time[s]')\n",
    "plt.legend()\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('Correlation coefficients for each timewindow along seismogram')\n",
    "plt.pcolormesh(timevec, BAZ, corr_zerolag, cmap='RdGy_r', vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.xlabel('time[s]')\n",
    "plt.ylabel('backazimuth[deg]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
